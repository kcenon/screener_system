# [DP-002] Daily Price Ingestion DAG Implementation

## Metadata
- **Status**: TODO
- **Priority**: Critical
- **Assignee**: TBD
- **Estimated Time**: 12 hours
- **Sprint**: Sprint 1 (Week 1-2)
- **Tags**: #data-pipeline #airflow #critical

## Description
Implement Airflow DAG to fetch daily stock prices from KRX API and load into database. This is the primary data source for the platform.

## Subtasks
- [ ] KRX API Client
  - [ ] data_pipeline/scripts/krx_api_client.py
  - [ ] authenticate() - API key authentication
  - [ ] fetch_daily_prices(date) - fetch OHLCV data
  - [ ] Error handling and retries
  - [ ] Rate limiting (respect API limits)
- [ ] DAG Definition
  - [ ] data_pipeline/dags/daily_price_ingestion_dag.py
  - [ ] Schedule: Mon-Fri at 18:00 KST (cron: 0 18 * * 1-5)
  - [ ] catchup=False (don't backfill)
  - [ ] max_active_runs=1
- [ ] Task 1: Fetch KRX Prices
  - [ ] PythonOperator: fetch_krx_prices
  - [ ] Fetch data for execution_date
  - [ ] Store in XCom for next task
  - [ ] Retry: 3 times, 5-minute interval
- [ ] Task 2: Validate Price Data
  - [ ] PythonOperator: validate_price_data
  - [ ] Quality checks:
    - [ ] Required fields present (stock_code, close_price, volume)
    - [ ] Price relationships (high >= low, close within range)
    - [ ] Non-negative values
  - [ ] Filter invalid records
  - [ ] Push valid data to XCom
  - [ ] Fail if < 95% data is valid
- [ ] Task 3: Load to Database
  - [ ] PythonOperator: load_prices_to_db
  - [ ] UPSERT to daily_prices table
  - [ ] Batch commits (1000 rows)
  - [ ] Log inserted/updated counts
- [ ] Task 4: Check Data Completeness
  - [ ] PythonOperator: check_data_completeness
  - [ ] Compare active stocks vs prices loaded
  - [ ] Calculate completeness percentage
  - [ ] Alert if < 95% complete
- [ ] Task 5: Refresh TimescaleDB Aggregates
  - [ ] PostgresOperator: refresh_timescale_aggregates
  - [ ] REFRESH MATERIALIZED VIEW daily_prices_weekly
  - [ ] REFRESH MATERIALIZED VIEW daily_prices_monthly
- [ ] Task 6: Trigger Indicator Calculation
  - [ ] TriggerDagRunOperator: trigger_indicator_calculation
  - [ ] Trigger indicator_calculation DAG
- [ ] Task 7: Log Ingestion Status
  - [ ] PythonOperator: log_ingestion_status
  - [ ] INSERT into data_ingestion_log table
  - [ ] Record counts, status, timestamps
  - [ ] Always run (trigger_rule='all_done')
- [ ] Error Handling
  - [ ] on_failure_callback - send email alert
  - [ ] Retry strategy: exponential backoff
  - [ ] Partial success if â‰¥95% complete

## Acceptance Criteria
- [ ] **DAG Visibility**
  - [ ] DAG appears in Airflow UI
  - [ ] No parsing errors
  - [ ] Schedule correctly set (Mon-Fri 18:00 KST)
- [ ] **Manual Trigger Test**
  - [ ] Manual trigger successful
  - [ ] All tasks complete successfully
  - [ ] Data loaded into daily_prices table
- [ ] **Data Quality**
  - [ ] All active stocks have price data
  - [ ] Prices pass validation checks
  - [ ] No duplicate records (stock_code, trade_date unique)
- [ ] **Performance**
  - [ ] Full DAG run < 10 minutes
  - [ ] fetch_krx_prices task < 5 minutes
  - [ ] load_prices_to_db task < 3 minutes
- [ ] **Error Handling**
  - [ ] Invalid data filtered correctly
  - [ ] Retries work for transient failures
  - [ ] Email alerts sent on critical failures
- [ ] **Data Completeness**
  - [ ] Completeness check accurate
  - [ ] Alert triggered if < 95%
- [ ] **Logging**
  - [ ] Ingestion status logged correctly
  - [ ] Airflow logs contain useful debugging info

## Dependencies
- **Depends on**: DP-001, DB-002
- **Blocks**: DP-003

## References
- **SDS.md**: Section 6.2 DAG Design
- **SDS.md**: Section 6.3 Data Quality Checks
- **data_pipeline/dags/daily_price_ingestion_dag.py** (implementation)
- **SRS.md**: REQ-DATA-001 Daily Price Ingestion

## Progress
- **0%** - Not started

## Notes
- **Critical for platform operation** - without this, no data
- KRX API credentials required (store in Airflow Variables/Secrets)
- Consider fallback data source if KRX API fails
- Monitor execution time (alert if > 15 minutes)
- Data quality > speed (better to fail than load bad data)
